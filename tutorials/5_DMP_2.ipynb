{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d87a449",
   "metadata": {},
   "source": [
    "# Tutorial: Discrete Dynamic Programming (2)\n",
    "\n",
    "## Computational Economics  (ECO309)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de127f0",
   "metadata": {},
   "source": [
    "### Job-Search Model\n",
    "\n",
    "- When unemployed in date, a job-seeker\n",
    "  - consumes unemployment benefit $c_t = \\underline{c}$\n",
    "  - receives in every date $t$ a job offer $w_t$\n",
    "    - $w_t$ is i.i.d., \n",
    "    - takes values $w_1, w_2, w_3$ with probabilities $p_1, p_2, p_3$\n",
    "  - if job-seeker accepts, becomes employed at rate $w_t$ in the next period\n",
    "  - else he stays unemployed\n",
    "  \n",
    "- When employed at rate $w$\n",
    "  - worker consumes salary $c_t = w$\n",
    "  - with small probability $\\lambda>0$ looses his job:\n",
    "    - starts next period unemployed\n",
    "  - otherwise stays employed at same rate\n",
    "- Objective: $\\max E_0 \\left\\{ \\sum \\beta^t \\log(w_t) \\right\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f19da7",
   "metadata": {},
   "source": [
    "__What are the states, the controls, the reward of this problem ? Write down the Bellman equation.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e00dc7",
   "metadata": {},
   "source": [
    "- States: \n",
    "    - Unemployed with offer $w_1$\n",
    "    - Unemployed with offer $w_2$\n",
    "    - Unemployed with offer $w_3$\n",
    "    - Employed at $w_1$\n",
    "    - Employed at $w_2$\n",
    "    - Employed at $w_3$\n",
    "- Controls:\n",
    "    - Unemployed with offer $w_1$ : accept/reject\n",
    "    - Unemployed with offer $w_2$ : accept/reject\n",
    "    - Unemployed with offer $w_3$ : accept/reject\n",
    "    - Employed at $w_1$ : None\n",
    "    - Employed at $w_2$ : None\n",
    "    - Employed at $w_3$ : None\n",
    "- Reward\n",
    "    - Unemployed at wage $w$: $\\log(underline{c})$\n",
    "    - Employed at wage $w$: $\\log(w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7072a",
   "metadata": {},
   "source": [
    "__Define a parameter structure for the model.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac34080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Parameters\n",
    "    p::Vector\n",
    "    w::Vector\n",
    "    λ::Float64\n",
    "    β::Float64\n",
    "    cbar::Float64\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "faa9ea4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameters([0.2, 0.6, 0.2], [0.9, 1.0, 1.1], 0.05, 0.9, 0.95)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parameters(\n",
    "    [0.2, 0.6, 0.2],\n",
    "    [0.9, 1.0, 1.1],\n",
    "    0.05,\n",
    "    0.9,\n",
    "    0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae7b4b",
   "metadata": {},
   "source": [
    "__Define a function  `value_update(V_U::Vector{Float64}, V_E::Vector{Float64}, x::Vector{Bool}, p::Parameters)::Tuple{Vector, Vector}`, which takes in value functions tomorrow and a policy vector and return updated values for today.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e7e1277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0 = [false, false, false]\n",
    "V_U_0 = [0.0, 0.0, 0.0]\n",
    "V_E_0 = [0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8edf81bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value_update (generic function with 2 methods)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function value_update(V_U::Vector, V_E::Vector, x::Vector{Bool}, p::Parameters)\n",
    "   \n",
    "    n_V_U = zeros(3)\n",
    "    n_V_E = zeros(3)\n",
    "    \n",
    "    # fill n_V_E (employed state)\n",
    "    for i=1:3\n",
    "        w_i = p.w[i]::Float64 # current wage\n",
    "        r = log(w_i) # current felicity\n",
    "        C_V_E = (1-p.λ)*p.β*V_E[i]\n",
    "        C_V_U = p.λ*p.β*sum(  p.p[j]*V_U[j] for j=1:3 )\n",
    "        n_V_E[i] = r + C_V_E + C_V_U\n",
    "    end\n",
    "    \n",
    "    # fill n_V_U\n",
    "    for i=1:3\n",
    "        r = log(p.cbar) # current reward\n",
    "        if x[i]==true\n",
    "            C_V = p.β*V_E[i]\n",
    "        else\n",
    "            C_V = p.β*sum(p.p[j]*V_U[j] for j=1:3) \n",
    "        end\n",
    "        n_V_U[i] = r + C_V\n",
    "    end\n",
    "    \n",
    "    return (n_V_U, n_V_E)\n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cab51c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-1.6094379124341003, -1.6094379124341003, -1.6094379124341003], [-0.10536051565782628, 0.0, 0.09531017980432493])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_U, V_E = value_update(V_U_0, V_E_0, x_0, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbf823",
   "metadata": {},
   "source": [
    "__Define a function `policy_eval(x::Vector{Bool}, p::Parameter)::Tuple{Vector, Vector}` which takes in a policy vector and returns the value(s) of following this policies forever. You can add relevant arguments to the function.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeff75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function policy_eval(x::Vector{Bool}, p::Parameter, V_U_0::Vector, V_E_0::Vector)::Tuple{Vector, Vector}\n",
    "#     ....\n",
    "# end\n",
    "\n",
    "# policy_eval(x::Vector{Bool}, p::Parameter) = policy_eval(x,p, zeros(3), zeros(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "380b8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.3, 0.3]\n",
    "b = [3.4, 3.2]\n",
    "using LinearAlgebra: norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4216dc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance (generic function with 1 method)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(a,b) = norm(a-b,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed3ebbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance (generic function with 2 methods)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(a::Tuple{Vector, Vector}, b::Tuple{Vector, Vector}) = distance(a[1],b[1]) + distance(a[2],b[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "171b0a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_eval (generic function with 5 methods)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function policy_eval(x::Vector{Bool}, p::Parameters, V_U::Vector=zeros(3),\n",
    "        V_E::Vector=zeros(3),\n",
    "    tol_η=1e-6, maxit=1000)::Tuple{Vector, Vector}\n",
    "    \n",
    "    for n=1:maxit\n",
    "       \n",
    "        n_V_U, n_V_E = value_update(V_U, V_E, x, p)\n",
    "        η = distance( (n_V_U, n_V_E), (V_U, V_E) )\n",
    "        if η<tol_η\n",
    "            return n_V_U, n_V_E\n",
    "        end\n",
    "        V_U, V_E = n_V_U, n_V_E\n",
    "    end    \n",
    "\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68a0617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-16.09437767883241, -16.09437767883241, -16.09437767883241], [-5.721430115203782, -4.994805869311957, -4.337494284476451])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_eval(x_0, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3634e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Vector{Bool}}:\n",
       " [0, 0, 0]\n",
       " [0, 0, 1]\n",
       " [0, 1, 0]\n",
       " [0, 1, 1]\n",
       " [1, 0, 0]\n",
       " [1, 0, 1]\n",
       " [1, 1, 0]\n",
       " [1, 1, 1]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_policies = [[i,j,k] for i=(false,true) for j=(false, true) for k=(false,true)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf103e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.5129314531275061, -0.5129314531275061, -0.5129314531275061], [-0.8858088390133, -0.1591845973552969, 0.4981269836502504])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_eval(all_policies[1],p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4524a616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Tuple{Vector{Float64}, Vector{Float64}}}:\n",
       " ([-0.5129314531275061, -0.5129314531275061, -0.5129314531275061], [-0.8858088390133, -0.1591845973552969, 0.4981269836502504])\n",
       " ([0.2178275908946779, 0.2178275908946779, 0.6238064425029485], [-0.6338248515901406, 0.09279939166451519, 0.7501109741144105])\n",
       " ([-0.14901119864138318, -0.08161854908109774, -0.14901119864138318], [-0.7603189502678954, -0.03369488717156144, 0.6236165323053081])\n",
       " ([0.049820558422034505, -0.0199141331469381, 0.5716662766192118], [-0.691758332658257, 0.03486589581906111, 0.6921774649012284])\n",
       " ([-0.932160399255396, -0.7824357865069405, -0.7824357865069405], [-0.9787413898882489, -0.25211714563564314, 0.4051944377170079])\n",
       " ([-0.7563955710258234, -0.2160825390833082, 0.48914658717492965], [-0.7834471406989734, -0.05682293942229902, 0.6004886050538931])\n",
       " ([-0.790507718586588, -0.13654590707184588, -0.32599919107860614], [-0.8213495134814646, -0.09472527688463331, 0.5625862995425273])\n",
       " ([-0.7299680492629766, -0.07600639247627608, 0.5155738850529066], [-0.754083245720711, -0.027459156115519127, 0.6298522873415293])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_values = [policy_eval(pol,p) for pol in all_policies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cce04cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×6 Matrix{Float64}:\n",
       " -0.512931   -0.512931   -0.512931  -0.885809  -0.159185   0.498127\n",
       "  0.217828    0.217828    0.623806  -0.633825   0.0927994  0.750111\n",
       " -0.149011   -0.0816185  -0.149011  -0.760319  -0.0336949  0.623617\n",
       "  0.0498206  -0.0199141   0.571666  -0.691758   0.0348659  0.692177\n",
       " -0.93216    -0.782436   -0.782436  -0.978741  -0.252117   0.405194\n",
       " -0.756396   -0.216083    0.489147  -0.783447  -0.0568229  0.600489\n",
       " -0.790508   -0.136546   -0.325999  -0.82135   -0.0947253  0.562586\n",
       " -0.729968   -0.0760064   0.515574  -0.754083  -0.0274592  0.629852"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat([reshape(cat(v[1], v[2]; dims=1),1,6) for v in all_values]..., dims=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff7903a",
   "metadata": {},
   "source": [
    "__Define a function `bellman_step(V_E::Vector, V_U::Vector, p::Parameters)::Tuple{Vector, Vector, Vector}` which returns updated values, together with improved policy rules.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "89b642a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bellman_step (generic function with 1 method)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function bellman_step(V_U::Vector, V_E::Vector, p::Parameters)\n",
    "   \n",
    "    n_V_U = zeros(3)\n",
    "    n_V_E = zeros(3)\n",
    "    x = zeros(Bool, 3)\n",
    "    \n",
    "    # fill n_V_E (employed state)\n",
    "    for i=1:3\n",
    "        w_i = p.w[i]::Float64 # current wage\n",
    "        r = log(w_i) # current felicity\n",
    "        C_V_E = (1-p.λ)*p.β*V_E[i]\n",
    "        C_V_U = p.λ*p.β*sum(  p.p[j]*V_U[j] for j=1:3 )\n",
    "        n_V_E[i] = r + C_V_E + C_V_U\n",
    "    end\n",
    "    \n",
    "    # fill n_V_U\n",
    "    for i=1:3\n",
    "        r = log(p.cbar) # current reward\n",
    "        C_V_accept = p.β*V_E[i]\n",
    "        C_V_reject = p.β*sum(p.p[j]*V_U[j] for j=1:3) \n",
    "        C_V = max(C_V_accept, C_V_reject)\n",
    "        x[i] = C_V_accept>C_V_reject    \n",
    "        n_V_U[i] = r + C_V\n",
    "    end\n",
    "    \n",
    "    return (n_V_U, n_V_E, x)\n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "395462a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-1.6094379124341003, -1.6094379124341003, -1.6094379124341003], [-0.10536051565782628, 0.0, 0.09531017980432493])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bellman_step(V_U_0, V_E_0, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce6b08",
   "metadata": {},
   "source": [
    "__Implement Value Function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bc5986f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vfi (generic function with 1 method)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vfi(p; maxit=1000, tol_η=1e-6, verbose=true)\n",
    "    V_U, V_E = zeros(3), zeros(3)\n",
    "    η_0 = 1\n",
    "    for it=1:maxit\n",
    "        n_V_U, n_V_E, x = bellman_step(V_U, V_E, p)\n",
    "        η = distance( (n_V_U, n_V_E), (V_U, V_E))\n",
    "        λ = η/η_0\n",
    "        η_0 = η\n",
    "        if verbose\n",
    "            println(\"$it : $η : $λ\")\n",
    "        end\n",
    "        if η<tol_η\n",
    "            return (n_V_U, n_V_E, x)\n",
    "        end\n",
    "        V_U, V_E = n_V_U, n_V_E\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b2c3291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000341 seconds (13.27 k allocations: 263.844 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.21782763098990254, 0.21782763098990254, 0.6238064825981732], [-0.6338248114949159, 0.09279943175973977, 0.750111014209635], Bool[0, 0, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time V_U, V_E, x = vfi(p, verbose=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e11bd",
   "metadata": {},
   "source": [
    "__Implement Policy Iteration and compare rates of convergence.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1206a2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vfi_improved (generic function with 1 method)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vfi_improved(p; maxit=1000, tol_η=1e-6, verbose=true)\n",
    "    V_U, V_E = zeros(3), zeros(3)\n",
    "    η_0 = 1\n",
    "    x0 = zeros(Bool, 3)\n",
    "    print(\"0 :   |\")\n",
    "    print(x0)\n",
    "    print(\"\\n\")\n",
    "    for it=1:maxit\n",
    "        \n",
    "        \n",
    "        V_U, V_E = policy_eval(x0, p)\n",
    "        n_V_U, n_V_E, x = bellman_step(V_U, V_E, p)\n",
    "        \n",
    "        \n",
    "        η = distance( x, x0)\n",
    "        x0 = x\n",
    "        \n",
    "        λ = η/η_0\n",
    "        η_0 = η\n",
    "        if verbose\n",
    "            print(\"$it : $η | \")\n",
    "            print(x)\n",
    "            print(\"| \")\n",
    "            print(V_U)\n",
    "            print(\"\\n\")\n",
    "        end\n",
    "        if η<tol_η\n",
    "            return (n_V_U, n_V_E, x)\n",
    "        end\n",
    "        V_U, V_E = n_V_U, n_V_E\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "75d8187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :   |Bool[0, 0, 0]\n",
      "1 : 2.0 | Bool[0, 1, 1]| [-0.5129314531275061, -0.5129314531275061, -0.5129314531275061]\n",
      "2 : 1.0 | Bool[0, 0, 1]| [0.049820558422034505, -0.0199141331469381, 0.5716662766192118]\n",
      "3 : 0.0 | Bool[0, 0, 1]| [0.2178275908946779, 0.2178275908946779, 0.6238064425029485]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.21782773070714823, 0.21782773070714823, 0.6238065823154189], [-0.6338247125126616, 0.09279953112789542, 0.7501111139268809], Bool[0, 0, 1])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vfi_improved(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972540b6",
   "metadata": {},
   "source": [
    "__Discuss the Effects of the Parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c79be584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :   |Bool[0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.4466193414900138, -0.2924978136313429, 16.516087381483914], [-0.8036845010939739, -0.07706033871006676, 18.599145797751635], Bool[0, 1, 1])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parameters(\n",
    "    [0.2, 0.6, 0.2],\n",
    "    [0.9, 1.0, 15],\n",
    "    0.05,\n",
    "    0.9,\n",
    "    0.8\n",
    ")\n",
    "vfi_improved(p, verbose=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4742d53a",
   "metadata": {},
   "source": [
    "### Brock-Mirman Stochastic Growth model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9e27e",
   "metadata": {},
   "source": [
    "This is a neoclassical growth model with unpredictable shocks on productivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c892b4eb",
   "metadata": {},
   "source": [
    "Social planner tries to solve:\n",
    "\n",
    "$$\\max E_t \\left[ \\sum_{n=0}^{\\infty} \\beta^n \\log C_{t+n} \\right]$$\n",
    "\n",
    "s.t.\n",
    "\n",
    "$$K_{t+1} = Y_t - C_t$$\n",
    "$$Y_{t+1} = A_{t+1}K_{t+1}^\\alpha$$\n",
    "\n",
    "where $A_t$ is the level of productivity in period $t$. \n",
    "It can take  values $A^h=1.05$ and $A^l=0.95$. The transition between these two states are given by the matrix:\n",
    "$$P = \\begin{bmatrix}\n",
    "0.9, 0.1\\\\\n",
    "0.1, 0.9\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4329d",
   "metadata": {},
   "source": [
    "__What are the states? What are the controls? Is it possible to bound them in a natural way? Propose a discretization scheme.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323c3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15d94883",
   "metadata": {},
   "source": [
    "__Implement the Value Function Algorithm__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4114397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aac788a5",
   "metadata": {},
   "source": [
    "__Bonus: Propose some ideas to improve performances.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832c2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0120376",
   "metadata": {},
   "source": [
    "__Policy iteration__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e4ccf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
